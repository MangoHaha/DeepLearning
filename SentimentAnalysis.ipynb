{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MangoHaha/SentimentAnalysis/blob/investigate_new_Arch/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "839fc1317e1b7253241839bbfa2d40303c53a3f1",
        "id": "CDx4CA09GZG8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## General information\n",
        "\n",
        "In this kernel I'll work with data from Movie Review Sentiment Analysis Playground Competition.\n"
      ]
    },
    {
      "metadata": {
        "id": "Vq4S5_HIGpBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "64833d45-6068-47bd-c909-ccad95de83d4"
      },
      "cell_type": "code",
      "source": [
        "!pip install lightgbm wordcloud\n",
        "!pip install pydot && apt-get install graphviz\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.2.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "id": "9K7leB0DGZG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "816ebf24-84bb-4b41-b18e-a64f8b3cad51"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "import lightgbm as lgb\n",
        "from scipy import stats\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "pd.set_option('max_colwidth',400)\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from google.colab import files\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yoOIXlOaxB9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import dataset are stored inside my google drive"
      ]
    },
    {
      "metadata": {
        "id": "NOvuWhQPLPmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnmH5hSQxQYa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read dataset: train test submission"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": true,
        "id": "Qp7EQ0TrGZHB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/DeepLearning/train.tsv', sep=\"\\t\")\n",
        "test = pd.read_csv('/content/drive/My Drive/DeepLearning/test.tsv', sep=\"\\t\")\n",
        "sub = pd.read_csv('/content/drive/My Drive/DeepLearning/sampleSubmission.csv', sep=\",\")\n",
        "y = train['Sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rilTf7HZbM4y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This dataset is interesting for NLP researching. Sentences from original dataset were split in separate phrases and each of them has a sentiment label. Also a lot of phrases are really short which makes classifying them quite challenging.\n",
        "We can see than sentences were split in 18-20 phrases at average and a lot of phrases contain each other. Sometimes one word or even one punctuation mark influences the sentiment"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9b8d8423bb09068cb168b67f4756ee8b250fc8c",
        "id": "xBg-49HYGZHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "0dead139-94d3-4f93-b436-70ada08281ec"
      },
      "cell_type": "code",
      "source": [
        "#print(train.head(10))\n",
        "print(train.loc[train.SentenceId == 20])\n",
        "print('Average count of phrases per sentence in train is {0:.0f}.'.format(train.groupby('SentenceId')['Phrase'].count().mean()))\n",
        "print('Average count of phrases per sentence in test is {0:.0f}.'.format(test.groupby('SentenceId')['Phrase'].count().mean()))\n",
        "print('Number of phrases in train: {}. Number of sentences in train: {}.'.format(train.shape[0], len(train.SentenceId.unique())))\n",
        "print('Number of phrases in test: {}. Number of sentences in test: {}.'.format(test.shape[0], len(test.SentenceId.unique())))\n",
        "print('Average word length of phrases in train is {0:.0f}.'.format(np.mean(train['Phrase'].apply(lambda x: len(x.split())))))\n",
        "print('Average word length of phrases in test is {0:.0f}.'.format(np.mean(test['Phrase'].apply(lambda x: len(x.split())))))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     PhraseId  SentenceId  \\\n",
            "536       537          20   \n",
            "537       538          20   \n",
            "538       539          20   \n",
            "539       540          20   \n",
            "540       541          20   \n",
            "541       542          20   \n",
            "542       543          20   \n",
            "543       544          20   \n",
            "544       545          20   \n",
            "545       546          20   \n",
            "546       547          20   \n",
            "547       548          20   \n",
            "548       549          20   \n",
            "549       550          20   \n",
            "550       551          20   \n",
            "\n",
            "                                                   Phrase  Sentiment  \n",
            "536  It 's everything you 'd expect -- but nothing more .          2  \n",
            "537     's everything you 'd expect -- but nothing more .          1  \n",
            "538       's everything you 'd expect -- but nothing more          2  \n",
            "539          everything you 'd expect -- but nothing more          1  \n",
            "540                                            everything          2  \n",
            "541                     you 'd expect -- but nothing more          1  \n",
            "542                         'd expect -- but nothing more          2  \n",
            "543                                                    'd          2  \n",
            "544                            expect -- but nothing more          2  \n",
            "545                                 expect -- but nothing          2  \n",
            "546                                             expect --          2  \n",
            "547                                                expect          2  \n",
            "548                                           but nothing          2  \n",
            "549                                               nothing          1  \n",
            "550                                                  more          2  \n",
            "Average count of phrases per sentence in train is 18.\n",
            "Average count of phrases per sentence in test is 20.\n",
            "Number of phrases in train: 156060. Number of sentences in train: 8529.\n",
            "Number of phrases in test: 66292. Number of sentences in test: 3310.\n",
            "Average word length of phrases in train is 7.\n",
            "Average word length of phrases in test is 7.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tI8pN6fob_mC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On Overlapping sentences in both Train and Test set"
      ]
    },
    {
      "metadata": {
        "id": "7K_b0M-0Eye9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_test = pd.merge(test, train[[\"Phrase\", \"Sentiment\"]], on=\"Phrase\", how=\"inner\")\n",
        "print (\"Number of overlapping phrases  \", save_test.shape[0])\n",
        "print (\"% of neutral sentiment phrases\",save_test[(save_test['Sentiment'] == 2)].count()[0] /save_test.shape[0])\n",
        "save_test = save_test[save_test[\"Sentiment\"].notnull()]\n",
        "save_test.drop(['SentenceId', 'Phrase'], axis=1,inplace=True)\n",
        "save_test = save_test[save_test[\"Sentiment\"].notnull()]\n",
        "\n",
        "import math\n",
        "def get_sentiment(row):\n",
        "    old_s = row['Sentiment_x']\n",
        "    new_s = row['Sentiment_y']\n",
        "    if math.isnan(new_s):\n",
        "        return int(old_s)\n",
        "    else:\n",
        "        return int(new_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "10dc8fc8d535ef492a3dab1b85b4052feec756ee",
        "id": "4qTvvMwYGZHq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Thoughts on feature processing and engineering"
      ]
    },
    {
      "metadata": {
        "_uuid": "d5d018a694d10cbd9e8e89c26d5227fdb9cf8c0b",
        "id": "lUzx6-B0GZHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So, we have only phrases as data. And a phrase can contain a single word. And one punctuation mark can cause phrase to receive a different sentiment. Also assigned sentiments can be strange. This means several things:\n",
        "- using stopwords can be a bad idea, especially when phrases contain one single stopword;\n",
        "- puntuation could be important, so it should be used;\n",
        "- ngrams are necessary to get the most info from data;\n",
        "- using features like word count or sentence length won't be useful;"
      ]
    },
    {
      "metadata": {
        "_uuid": "398461363c7a395e2a982e07e8ac6fccaee139c1",
        "id": "D-qyZxyVGZIG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb29ec027df57f6597dbef976645dc8d151e1618",
        "id": "AwnzDD_0GZIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, LeakyReLU\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9dfd0b8fa2c79bfa206d2fe8e35fbec444418f5c",
        "id": "x2VpwGsgGZIS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = \"/content/drive/My Drive/DeepLearning/crawl-300d-2M.vec\"\n",
        "#embedding_path = \"/content/drive/My Drive/DeepLearning/glove.twitter.27B.25d.txt\"\n",
        "#embed_size = 25\n",
        "embed_size = 300\n",
        "max_features = 30000\n",
        "\n",
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2881c29f82578b4a373b52d2c7b96a2e73bfd80",
        "id": "TP2z0XJhGZIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(lower = True, filters='')\n",
        "full_text = list(train['Phrase'].values) + list(test['Phrase'].values)\n",
        "tk.fit_on_texts(full_text)\n",
        "train_tokenized = tk.texts_to_sequences(train['Phrase'])\n",
        "test_tokenized = tk.texts_to_sequences(test['Phrase'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bcb80cf8a59ca779a0be1ab235a1e9da2f4b175b",
        "id": "b6bErvirGZIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 50\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "365c0d607d55a78c5890268b9c168eb12a211855",
        "id": "4AlRADppGZIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "y_ohe = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "ohe.fit(train[\"Sentiment\"].values.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2cpGj5WcMsH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model 1"
      ]
    },
    {
      "metadata": {
        "_uuid": "95f52b1f6de4e939c8d21e3525503912282fbd47",
        "id": "fdY5hCa9GZIf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "An attempt at ensemble:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8187e167ce93f0eb69f59cb9d7fedc4637a77cfe",
        "id": "jUBolZU1GZIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
        "    \n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "    \n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n",
        "    \n",
        "    \n",
        "    x_conv3 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x_conv3)\n",
        "    \n",
        "    x_conv4 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
        "    avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4)\n",
        "    max_pool2_lstm = GlobalMaxPooling1D()(x_conv4)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool2_lstm, max_pool2_lstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(5, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjh0IK94gE7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Print the Summary and Arch of the model"
      ]
    },
    {
      "metadata": {
        "id": "yrvsOTvmOPvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "2cc4f555-8a55-483e-ebd2-3a41fb6cbd4a"
      },
      "cell_type": "code",
      "source": [
        "trained_model1.summary()\n",
        "SVG(model_to_dot(trained_model1,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 50, 300)      5843700     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_1 (SpatialDro (None, 50, 300)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 50, 128)      140544      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 50, 128)      187392      spatial_dropout1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 48, 32)       12320       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 48, 32)       12320       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 48, 32)       12320       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 48, 32)       12320       bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 32)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 32)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 32)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 32)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 32)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 32)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_4 (GlobalM (None, 32)           0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_average_pooling1d_3[0][0] \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_average_pooling1d_4[0][0] \n",
            "                                                                 global_max_pooling1d_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256)          1024        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           16448       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64)           256         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           2080        batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            165         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,240,889\n",
            "Trainable params: 396,549\n",
            "Non-trainable params: 5,844,340\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7cn0Rl5R6KJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "K folds Validation"
      ]
    },
    {
      "metadata": {
        "id": "O9OLbhyJTfMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "6ee8bd27-0d55-4636-c033-93374d3602a6"
      },
      "cell_type": "code",
      "source": [
        "NUM_FOLDS = 5\n",
        "train[\"fold_id\"] = train[\"SentenceId\"].apply(lambda x: x%NUM_FOLDS)\n",
        "test_preds = np.zeros((test.shape[0], 5))\n",
        "file_path = \"/content/drive/My Drive/DeepLearning/best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 2)\n",
        "\n",
        "print(\"Building the model...\")\n",
        "model1 = build_model1(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)\n",
        "\n",
        "for i in range(NUM_FOLDS):\n",
        "    print(\"FOLD\", i+1)    \n",
        "    print(\"Splitting the data into train and validation...\")\n",
        "    train_seq, val_seq = X_train[train[\"fold_id\"] != i], X_train[train[\"fold_id\"] == i]\n",
        "    y_train = ohe.transform(train[train[\"fold_id\"] != i][\"Sentiment\"].values.reshape(-1, 1))\n",
        "    y_val = ohe.transform(train[train[\"fold_id\"] == i][\"Sentiment\"].values.reshape(-1, 1))        \n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model1.fit(train_seq, y_train, validation_data = (val_seq, y_val), batch_size = 128, epochs = 15, verbose = 1, callbacks = [early_stop]) \n",
        "    model1.save_weights(file_path)  \n",
        "    test_preds += model1.predict([X_test], batch_size=1024, verbose=1)    \n",
        "    print()\n",
        "    \n",
        "print(\"Save model after cross-validation...\")\n",
        "model1.save_weights(file_path)   \n",
        "test_preds /= NUM_FOLDS\n",
        "\n",
        "\n",
        "print(\"Make the submission ready...\")\n",
        "sub = pd.read_csv('/content/drive/My Drive/DeepLearning/sampleSubmission.csv', sep=\",\")\n",
        "\n",
        "pred = model1.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "submission = pd.DataFrame({'PhraseId':test['PhraseId'],'Sentiment': predictions})\n",
        "submission =pd.merge(submission, save_test, on='PhraseId', how='left')\n",
        "submission[\"Sentiment\"] = submission.apply(get_sentiment, axis=1)\n",
        "submission.drop(['Sentiment_x', 'Sentiment_y'], axis=1,inplace=True)\n",
        "submission[\"Sentiment\"] = submission[\"Sentiment\"].astype(int)\n",
        "submission.to_csv(\"/content/drive/My Drive/DeepLearning/blend.csv\", index=False)\n",
        "\n",
        "predictions = np.round(np.argmax(test_preds, axis=1)).astype(int)\n",
        "submission = pd.DataFrame({'PhraseId':test['PhraseId'],'Sentiment': predictions})\n",
        "submission =pd.merge(submission, save_test, on='PhraseId', how='left')\n",
        "submission[\"Sentiment\"] = submission.apply(get_sentiment, axis=1)\n",
        "submission.drop(['Sentiment_x', 'Sentiment_y'], axis=1,inplace=True)\n",
        "submission[\"Sentiment\"] = submission[\"Sentiment\"].astype(int)\n",
        "submission.to_csv(\"/content/drive/My Drive/DeepLearning/avg_blend.csv\", index=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building the model...\n",
            "FOLD 1\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125230 samples, validate on 30830 samples\n",
            "Epoch 1/15\n",
            "125230/125230 [==============================] - 70s 557us/step - loss: 0.3728 - acc: 0.8319 - val_loss: 0.3122 - val_acc: 0.8580\n",
            "Epoch 2/15\n",
            "125230/125230 [==============================] - 62s 493us/step - loss: 0.3281 - acc: 0.8515 - val_loss: 0.3031 - val_acc: 0.8599\n",
            "Epoch 3/15\n",
            "125230/125230 [==============================] - 62s 492us/step - loss: 0.3184 - acc: 0.8549 - val_loss: 0.3007 - val_acc: 0.8629\n",
            "Epoch 4/15\n",
            "125230/125230 [==============================] - 62s 494us/step - loss: 0.3115 - acc: 0.8572 - val_loss: 0.2998 - val_acc: 0.8620\n",
            "Epoch 5/15\n",
            "125230/125230 [==============================] - 62s 493us/step - loss: 0.3046 - acc: 0.8599 - val_loss: 0.2952 - val_acc: 0.8663\n",
            "Epoch 6/15\n",
            "125230/125230 [==============================] - 62s 493us/step - loss: 0.2976 - acc: 0.8632 - val_loss: 0.2900 - val_acc: 0.8669\n",
            "Epoch 7/15\n",
            "125230/125230 [==============================] - 61s 489us/step - loss: 0.2941 - acc: 0.8648 - val_loss: 0.2888 - val_acc: 0.8678\n",
            "Epoch 8/15\n",
            "125230/125230 [==============================] - 61s 491us/step - loss: 0.2897 - acc: 0.8668 - val_loss: 0.2901 - val_acc: 0.8676\n",
            "Epoch 9/15\n",
            "125230/125230 [==============================] - 61s 490us/step - loss: 0.2868 - acc: 0.8683 - val_loss: 0.2883 - val_acc: 0.8687\n",
            "Epoch 10/15\n",
            "125230/125230 [==============================] - 61s 489us/step - loss: 0.2835 - acc: 0.8698 - val_loss: 0.2893 - val_acc: 0.8686\n",
            "Epoch 11/15\n",
            "125230/125230 [==============================] - 61s 490us/step - loss: 0.2812 - acc: 0.8710 - val_loss: 0.2877 - val_acc: 0.8688\n",
            "Epoch 12/15\n",
            "125230/125230 [==============================] - 61s 490us/step - loss: 0.2783 - acc: 0.8726 - val_loss: 0.2865 - val_acc: 0.8691\n",
            "Epoch 13/15\n",
            "125230/125230 [==============================] - 61s 490us/step - loss: 0.2762 - acc: 0.8739 - val_loss: 0.2898 - val_acc: 0.8666\n",
            "Epoch 14/15\n",
            "125230/125230 [==============================] - 61s 491us/step - loss: 0.2745 - acc: 0.8749 - val_loss: 0.2872 - val_acc: 0.8696\n",
            "66292/66292 [==============================] - 4s 64us/step\n",
            "\n",
            "FOLD 2\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124608 samples, validate on 31452 samples\n",
            "Epoch 1/15\n",
            "124608/124608 [==============================] - 61s 488us/step - loss: 0.2808 - acc: 0.8720 - val_loss: 0.2489 - val_acc: 0.8887\n",
            "Epoch 2/15\n",
            "124608/124608 [==============================] - 61s 491us/step - loss: 0.2782 - acc: 0.8728 - val_loss: 0.2524 - val_acc: 0.8877\n",
            "Epoch 3/15\n",
            "124608/124608 [==============================] - 61s 490us/step - loss: 0.2751 - acc: 0.8746 - val_loss: 0.2513 - val_acc: 0.8877\n",
            "66292/66292 [==============================] - 3s 48us/step\n",
            "\n",
            "FOLD 3\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125022 samples, validate on 31038 samples\n",
            "Epoch 1/15\n",
            "125022/125022 [==============================] - 61s 488us/step - loss: 0.2765 - acc: 0.8740 - val_loss: 0.2355 - val_acc: 0.8952\n",
            "Epoch 2/15\n",
            "125022/125022 [==============================] - 61s 490us/step - loss: 0.2742 - acc: 0.8755 - val_loss: 0.2378 - val_acc: 0.8928\n",
            "Epoch 3/15\n",
            "125022/125022 [==============================] - 61s 489us/step - loss: 0.2727 - acc: 0.8764 - val_loss: 0.2400 - val_acc: 0.8924\n",
            "66292/66292 [==============================] - 3s 48us/step\n",
            "\n",
            "FOLD 4\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124609 samples, validate on 31451 samples\n",
            "Epoch 1/15\n",
            "124609/124609 [==============================] - 61s 489us/step - loss: 0.2718 - acc: 0.8770 - val_loss: 0.2355 - val_acc: 0.8946\n",
            "Epoch 2/15\n",
            "124609/124609 [==============================] - 61s 490us/step - loss: 0.2693 - acc: 0.8779 - val_loss: 0.2391 - val_acc: 0.8937\n",
            "Epoch 3/15\n",
            "124609/124609 [==============================] - 61s 491us/step - loss: 0.2682 - acc: 0.8788 - val_loss: 0.2409 - val_acc: 0.8921\n",
            "66292/66292 [==============================] - 3s 48us/step\n",
            "\n",
            "FOLD 5\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124771 samples, validate on 31289 samples\n",
            "Epoch 1/15\n",
            "124771/124771 [==============================] - 61s 489us/step - loss: 0.2695 - acc: 0.8780 - val_loss: 0.2309 - val_acc: 0.8969\n",
            "Epoch 2/15\n",
            "124771/124771 [==============================] - 61s 492us/step - loss: 0.2673 - acc: 0.8791 - val_loss: 0.2326 - val_acc: 0.8955\n",
            "Epoch 3/15\n",
            "124771/124771 [==============================] - 61s 491us/step - loss: 0.2664 - acc: 0.8798 - val_loss: 0.2360 - val_acc: 0.8939\n",
            "66292/66292 [==============================] - 3s 49us/step\n",
            "\n",
            "Save model after cross-validation...\n",
            "Make the submission ready...\n",
            "66292/66292 [==============================] - 3s 48us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9I07QVa8OYB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Print the Arch of trained model"
      ]
    },
    {
      "metadata": {
        "id": "rpqwTRtOn3Be",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model2(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "\n",
        "    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n",
        "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
        "    \n",
        "    x_conv1 = Conv1D(128, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_gru)\n",
        "    x_conv1 = Conv1D(64, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_conv1)\n",
        "    x_conv1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_conv1)\n",
        "\n",
        "      \n",
        "    avg_pool1_gru = GlobalAveragePooling1D()(x_conv1)\n",
        "    max_pool1_gru = GlobalMaxPooling1D()(x_conv1)\n",
        "    \n",
        "    x_conv2 = Conv1D(128, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_gru)\n",
        "    x_conv2 = Conv1D(64, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_conv2)\n",
        "    x_conv2 = Conv1D(conv_size, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_conv2)    \n",
        "    avg_pool2_gru = GlobalAveragePooling1D()(x_conv2)\n",
        "    max_pool2_gru = GlobalMaxPooling1D()(x_conv2)\n",
        "    \n",
        "    \n",
        "    x_conv3 = Conv1D(128, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_lstm)\n",
        "    x_conv3 = Conv1D(64, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_conv3)\n",
        "    x_conv3 = Conv1D(conv_size, kernel_size=kernel_size1, padding='causal', kernel_initializer='he_uniform')(x_conv3)\n",
        "    avg_pool1_lstm = GlobalAveragePooling1D()(x_conv3)\n",
        "    max_pool1_lstm = GlobalMaxPooling1D()(x_conv3)\n",
        "    \n",
        "    x_conv4 = Conv1D(128, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_lstm)\n",
        "    x_conv4 = Conv1D(64, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_conv4)\n",
        "    x_conv4 = Conv1D(conv_size, kernel_size=kernel_size2, padding='causal', kernel_initializer='he_uniform')(x_conv4)\n",
        "\n",
        "    avg_pool2_lstm = GlobalAveragePooling1D()(x_conv4)\n",
        "    max_pool2_lstm = GlobalMaxPooling1D()(x_conv4)\n",
        "    \n",
        "    \n",
        "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool2_gru, max_pool2_gru,\n",
        "                    avg_pool1_lstm, max_pool1_lstm, avg_pool2_lstm, max_pool2_lstm])\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
        "    x = Dense(5, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FZamFj3U7z5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3134
        },
        "outputId": "2b0ec71d-a9d5-4d66-c75a-768d9ddcdcaa"
      },
      "cell_type": "code",
      "source": [
        "trained_model2 = build_model2(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)\n",
        "trained_model2.summary()\n",
        "SVG(model_to_dot(trained_model2,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 50, 300)      5843700     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 50, 300)      0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 50, 128)      140544      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 50, 128)      187392      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 50, 128)      49280       bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 50, 128)      49280       bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_19 (Conv1D)              (None, 50, 128)      49280       bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 50, 128)      49280       bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 50, 64)       24640       conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_17 (Conv1D)              (None, 50, 64)       24640       conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_20 (Conv1D)              (None, 50, 64)       24640       conv1d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 50, 64)       24640       conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 50, 32)       6176        conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_18 (Conv1D)              (None, 50, 32)       6176        conv1d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 50, 32)       6176        conv1d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_24 (Conv1D)              (None, 50, 32)       6176        conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_5 (Glo (None, 32)           0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_5 (GlobalM (None, 32)           0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 32)           0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 32)           0           conv1d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_7 (Glo (None, 32)           0           conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_7 (GlobalM (None, 32)           0           conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_8 (Glo (None, 32)           0           conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_8 (GlobalM (None, 32)           0           conv1d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           global_average_pooling1d_5[0][0] \n",
            "                                                                 global_max_pooling1d_5[0][0]     \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "                                                                 global_max_pooling1d_6[0][0]     \n",
            "                                                                 global_average_pooling1d_7[0][0] \n",
            "                                                                 global_max_pooling1d_7[0][0]     \n",
            "                                                                 global_average_pooling1d_8[0][0] \n",
            "                                                                 global_max_pooling1d_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256)          1024        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 64)           16448       batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64)           256         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 32)           2080        batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 5)            165         dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,511,993\n",
            "Trainable params: 667,653\n",
            "Non-trainable params: 5,844,340\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"1300pt\" viewBox=\"0.00 0.00 4006.00 1300.00\" width=\"4006pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1296)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1296 4002,-1296 4002,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140252887122888 -->\n<g class=\"node\" id=\"node1\">\n<title>140252887122888</title>\n<polygon fill=\"none\" points=\"2039.5,-1245.5 2039.5,-1291.5 2310.5,-1291.5 2310.5,-1245.5 2039.5,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2106\" y=\"-1264.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"2172.5,-1245.5 2172.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2201.5\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"2172.5,-1268.5 2230.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2201.5\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"2230.5,-1245.5 2230.5,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2270.5\" y=\"-1276.3\">(None, 50)</text>\n<polyline fill=\"none\" points=\"2230.5,-1268.5 2310.5,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2270.5\" y=\"-1253.3\">(None, 50)</text>\n</g>\n<!-- 140252887303392 -->\n<g class=\"node\" id=\"node2\">\n<title>140252887303392</title>\n<polygon fill=\"none\" points=\"2005.5,-1162.5 2005.5,-1208.5 2344.5,-1208.5 2344.5,-1162.5 2005.5,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091\" y=\"-1181.8\">embedding_2: Embedding</text>\n<polyline fill=\"none\" points=\"2176.5,-1162.5 2176.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2205.5\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"2176.5,-1185.5 2234.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2205.5\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"2234.5,-1162.5 2234.5,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2289.5\" y=\"-1193.3\">(None, 50)</text>\n<polyline fill=\"none\" points=\"2234.5,-1185.5 2344.5,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2289.5\" y=\"-1170.3\">(None, 50, 300)</text>\n</g>\n<!-- 140252887122888&#45;&gt;140252887303392 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140252887122888-&gt;140252887303392</title>\n<path d=\"M2175,-1245.3799C2175,-1237.1745 2175,-1227.7679 2175,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2178.5001,-1218.784 2175,-1208.784 2171.5001,-1218.784 2178.5001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252887303728 -->\n<g class=\"node\" id=\"node3\">\n<title>140252887303728</title>\n<polygon fill=\"none\" points=\"1966.5,-1079.5 1966.5,-1125.5 2383.5,-1125.5 2383.5,-1079.5 1966.5,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091\" y=\"-1098.8\">spatial_dropout1d_2: SpatialDropout1D</text>\n<polyline fill=\"none\" points=\"2215.5,-1079.5 2215.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2244.5\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"2215.5,-1102.5 2273.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2244.5\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"2273.5,-1079.5 2273.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2328.5\" y=\"-1110.3\">(None, 50, 300)</text>\n<polyline fill=\"none\" points=\"2273.5,-1102.5 2383.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2328.5\" y=\"-1087.3\">(None, 50, 300)</text>\n</g>\n<!-- 140252887303392&#45;&gt;140252887303728 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140252887303392-&gt;140252887303728</title>\n<path d=\"M2175,-1162.3799C2175,-1154.1745 2175,-1144.7679 2175,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2178.5001,-1135.784 2175,-1125.784 2171.5001,-1135.784 2178.5001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252886456976 -->\n<g class=\"node\" id=\"node4\">\n<title>140252886456976</title>\n<polygon fill=\"none\" points=\"1409.5,-996.5 1409.5,-1042.5 1936.5,-1042.5 1936.5,-996.5 1409.5,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1589\" y=\"-1015.8\">bidirectional_3(cu_dnngru_2): Bidirectional(CuDNNGRU)</text>\n<polyline fill=\"none\" points=\"1768.5,-996.5 1768.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1797.5\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"1768.5,-1019.5 1826.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1797.5\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"1826.5,-996.5 1826.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1881.5\" y=\"-1027.3\">(None, 50, 300)</text>\n<polyline fill=\"none\" points=\"1826.5,-1019.5 1936.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1881.5\" y=\"-1004.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252887303728&#45;&gt;140252886456976 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140252887303728-&gt;140252886456976</title>\n<path d=\"M2035.8317,-1079.4901C1969.4565,-1068.5157 1889.9664,-1055.3729 1822.3293,-1044.1899\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1822.8761,-1040.7329 1812.4391,-1042.5547 1821.7342,-1047.6391 1822.8761,-1040.7329\" stroke=\"#000000\"/>\n</g>\n<!-- 140252876423856 -->\n<g class=\"node\" id=\"node5\">\n<title>140252876423856</title>\n<polygon fill=\"none\" points=\"2266,-996.5 2266,-1042.5 2806,-1042.5 2806,-996.5 2266,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2452\" y=\"-1015.8\">bidirectional_4(cu_dnnlstm_2): Bidirectional(CuDNNLSTM)</text>\n<polyline fill=\"none\" points=\"2638,-996.5 2638,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2667\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"2638,-1019.5 2696,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2667\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"2696,-996.5 2696,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2751\" y=\"-1027.3\">(None, 50, 300)</text>\n<polyline fill=\"none\" points=\"2696,-1019.5 2806,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2751\" y=\"-1004.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252887303728&#45;&gt;140252876423856 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140252887303728-&gt;140252876423856</title>\n<path d=\"M2275.0792,-1079.4901C2321.9309,-1068.7181 2377.8691,-1055.857 2425.9141,-1044.8106\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2426.7646,-1048.2065 2435.7261,-1042.5547 2425.1961,-1041.3844 2426.7646,-1048.2065\" stroke=\"#000000\"/>\n</g>\n<!-- 140252876426264 -->\n<g class=\"node\" id=\"node6\">\n<title>140252876426264</title>\n<polygon fill=\"none\" points=\"1024,-913.5 1024,-959.5 1332,-959.5 1332,-913.5 1024,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094\" y=\"-932.8\">conv1d_13: Conv1D</text>\n<polyline fill=\"none\" points=\"1164,-913.5 1164,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1193\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"1164,-936.5 1222,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1193\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"1222,-913.5 1222,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277\" y=\"-944.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"1222,-936.5 1332,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277\" y=\"-921.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252886456976&#45;&gt;140252876426264 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140252886456976-&gt;140252876426264</title>\n<path d=\"M1535.7723,-996.4901C1470.4568,-985.5382 1392.2621,-972.4268 1325.6572,-961.2587\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1325.9358,-957.7566 1315.4947,-959.5547 1324.7782,-964.6602 1325.9358,-957.7566\" stroke=\"#000000\"/>\n</g>\n<!-- 140252874037792 -->\n<g class=\"node\" id=\"node7\">\n<title>140252874037792</title>\n<polygon fill=\"none\" points=\"1519,-913.5 1519,-959.5 1827,-959.5 1827,-913.5 1519,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1589\" y=\"-932.8\">conv1d_16: Conv1D</text>\n<polyline fill=\"none\" points=\"1659,-913.5 1659,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1688\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"1659,-936.5 1717,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1688\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"1717,-913.5 1717,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-944.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"1717,-936.5 1827,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-921.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252886456976&#45;&gt;140252874037792 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140252886456976-&gt;140252874037792</title>\n<path d=\"M1673,-996.3799C1673,-988.1745 1673,-978.7679 1673,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1676.5001,-969.784 1673,-959.784 1669.5001,-969.784 1676.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873065528 -->\n<g class=\"node\" id=\"node8\">\n<title>140252873065528</title>\n<polygon fill=\"none\" points=\"2382,-913.5 2382,-959.5 2690,-959.5 2690,-913.5 2382,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2452\" y=\"-932.8\">conv1d_19: Conv1D</text>\n<polyline fill=\"none\" points=\"2522,-913.5 2522,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2551\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"2522,-936.5 2580,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2551\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"2580,-913.5 2580,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-944.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"2580,-936.5 2690,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-921.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252876423856&#45;&gt;140252873065528 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140252876423856-&gt;140252873065528</title>\n<path d=\"M2536,-996.3799C2536,-988.1745 2536,-978.7679 2536,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2539.5001,-969.784 2536,-959.784 2532.5001,-969.784 2539.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872716360 -->\n<g class=\"node\" id=\"node9\">\n<title>140252872716360</title>\n<polygon fill=\"none\" points=\"2909,-913.5 2909,-959.5 3217,-959.5 3217,-913.5 2909,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2979\" y=\"-932.8\">conv1d_22: Conv1D</text>\n<polyline fill=\"none\" points=\"3049,-913.5 3049,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3078\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"3049,-936.5 3107,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3078\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"3107,-913.5 3107,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3162\" y=\"-944.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"3107,-936.5 3217,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3162\" y=\"-921.3\">(None, 50, 128)</text>\n</g>\n<!-- 140252876423856&#45;&gt;140252872716360 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140252876423856-&gt;140252872716360</title>\n<path d=\"M2682.099,-996.4901C2751.9225,-985.4932 2835.5706,-972.319 2906.6703,-961.1212\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2907.2831,-964.5679 2916.6168,-959.5547 2906.194,-957.6531 2907.2831,-964.5679\" stroke=\"#000000\"/>\n</g>\n<!-- 140252876426488 -->\n<g class=\"node\" id=\"node10\">\n<title>140252876426488</title>\n<polygon fill=\"none\" points=\"685,-830.5 685,-876.5 993,-876.5 993,-830.5 685,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"755\" y=\"-849.8\">conv1d_14: Conv1D</text>\n<polyline fill=\"none\" points=\"825,-830.5 825,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"825,-853.5 883,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"854\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"883,-830.5 883,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"938\" y=\"-861.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"883,-853.5 993,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"938\" y=\"-838.3\">(None, 50, 64)</text>\n</g>\n<!-- 140252876426264&#45;&gt;140252876426488 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140252876426264-&gt;140252876426488</title>\n<path d=\"M1084.0198,-913.4901C1040.2071,-902.7631 987.9326,-889.9643 942.9426,-878.9491\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"943.7085,-875.5333 933.163,-876.5547 942.0438,-882.3325 943.7085,-875.5333\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873658440 -->\n<g class=\"node\" id=\"node11\">\n<title>140252873658440</title>\n<polygon fill=\"none\" points=\"1519,-830.5 1519,-876.5 1827,-876.5 1827,-830.5 1519,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1589\" y=\"-849.8\">conv1d_17: Conv1D</text>\n<polyline fill=\"none\" points=\"1659,-830.5 1659,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1688\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"1659,-853.5 1717,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1688\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"1717,-830.5 1717,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-861.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"1717,-853.5 1827,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-838.3\">(None, 50, 64)</text>\n</g>\n<!-- 140252874037792&#45;&gt;140252873658440 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140252874037792-&gt;140252873658440</title>\n<path d=\"M1673,-913.3799C1673,-905.1745 1673,-895.7679 1673,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1676.5001,-886.784 1673,-876.784 1669.5001,-886.784 1676.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873301800 -->\n<g class=\"node\" id=\"node12\">\n<title>140252873301800</title>\n<polygon fill=\"none\" points=\"2382,-830.5 2382,-876.5 2690,-876.5 2690,-830.5 2382,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2452\" y=\"-849.8\">conv1d_20: Conv1D</text>\n<polyline fill=\"none\" points=\"2522,-830.5 2522,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2551\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"2522,-853.5 2580,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2551\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"2580,-830.5 2580,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-861.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"2580,-853.5 2690,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-838.3\">(None, 50, 64)</text>\n</g>\n<!-- 140252873065528&#45;&gt;140252873301800 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140252873065528-&gt;140252873301800</title>\n<path d=\"M2536,-913.3799C2536,-905.1745 2536,-895.7679 2536,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2539.5001,-886.784 2536,-876.784 2532.5001,-886.784 2539.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872318312 -->\n<g class=\"node\" id=\"node13\">\n<title>140252872318312</title>\n<polygon fill=\"none\" points=\"3010,-830.5 3010,-876.5 3318,-876.5 3318,-830.5 3010,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3080\" y=\"-849.8\">conv1d_23: Conv1D</text>\n<polyline fill=\"none\" points=\"3150,-830.5 3150,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3179\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"3150,-853.5 3208,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3179\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"3208,-830.5 3208,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3263\" y=\"-861.3\">(None, 50, 128)</text>\n<polyline fill=\"none\" points=\"3208,-853.5 3318,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3263\" y=\"-838.3\">(None, 50, 64)</text>\n</g>\n<!-- 140252872716360&#45;&gt;140252872318312 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140252872716360-&gt;140252872318312</title>\n<path d=\"M3091.1341,-913.3799C3102.5298,-904.0151 3115.8297,-893.0855 3127.9245,-883.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"3130.1627,-885.8371 3135.6665,-876.784 3125.7183,-880.429 3130.1627,-885.8371\" stroke=\"#000000\"/>\n</g>\n<!-- 140252874209656 -->\n<g class=\"node\" id=\"node14\">\n<title>140252874209656</title>\n<polygon fill=\"none\" points=\"604,-747.5 604,-793.5 904,-793.5 904,-747.5 604,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-766.8\">conv1d_15: Conv1D</text>\n<polyline fill=\"none\" points=\"744,-747.5 744,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"744,-770.5 802,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"802,-747.5 802,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"853\" y=\"-778.3\">(None, 50, 64)</text>\n<polyline fill=\"none\" points=\"802,-770.5 904,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"853\" y=\"-755.3\">(None, 50, 32)</text>\n</g>\n<!-- 140252876426488&#45;&gt;140252874209656 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140252876426488-&gt;140252874209656</title>\n<path d=\"M815.3228,-830.3799C806.0063,-821.2827 795.1777,-810.7088 785.2354,-801.0005\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"787.4451,-798.2663 777.8451,-793.784 782.5546,-803.2746 787.4451,-798.2663\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873759488 -->\n<g class=\"node\" id=\"node15\">\n<title>140252873759488</title>\n<polygon fill=\"none\" points=\"1523,-747.5 1523,-793.5 1823,-793.5 1823,-747.5 1523,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1593\" y=\"-766.8\">conv1d_18: Conv1D</text>\n<polyline fill=\"none\" points=\"1663,-747.5 1663,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1692\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"1663,-770.5 1721,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1692\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"1721,-747.5 1721,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-778.3\">(None, 50, 64)</text>\n<polyline fill=\"none\" points=\"1721,-770.5 1823,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1772\" y=\"-755.3\">(None, 50, 32)</text>\n</g>\n<!-- 140252873658440&#45;&gt;140252873759488 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140252873658440-&gt;140252873759488</title>\n<path d=\"M1673,-830.3799C1673,-822.1745 1673,-812.7679 1673,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1676.5001,-803.784 1673,-793.784 1669.5001,-803.784 1676.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872917400 -->\n<g class=\"node\" id=\"node16\">\n<title>140252872917400</title>\n<polygon fill=\"none\" points=\"2386,-747.5 2386,-793.5 2686,-793.5 2686,-747.5 2386,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2456\" y=\"-766.8\">conv1d_21: Conv1D</text>\n<polyline fill=\"none\" points=\"2526,-747.5 2526,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2555\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"2526,-770.5 2584,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2555\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"2584,-747.5 2584,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-778.3\">(None, 50, 64)</text>\n<polyline fill=\"none\" points=\"2584,-770.5 2686,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2635\" y=\"-755.3\">(None, 50, 32)</text>\n</g>\n<!-- 140252873301800&#45;&gt;140252872917400 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140252873301800-&gt;140252872917400</title>\n<path d=\"M2536,-830.3799C2536,-822.1745 2536,-812.7679 2536,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2539.5001,-803.784 2536,-793.784 2532.5001,-803.784 2539.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872427000 -->\n<g class=\"node\" id=\"node17\">\n<title>140252872427000</title>\n<polygon fill=\"none\" points=\"3114,-747.5 3114,-793.5 3414,-793.5 3414,-747.5 3114,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3184\" y=\"-766.8\">conv1d_24: Conv1D</text>\n<polyline fill=\"none\" points=\"3254,-747.5 3254,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3283\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"3254,-770.5 3312,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3283\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"3312,-747.5 3312,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3363\" y=\"-778.3\">(None, 50, 64)</text>\n<polyline fill=\"none\" points=\"3312,-770.5 3414,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3363\" y=\"-755.3\">(None, 50, 32)</text>\n</g>\n<!-- 140252872318312&#45;&gt;140252872427000 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140252872318312-&gt;140252872427000</title>\n<path d=\"M3191.8556,-830.3799C3203.031,-821.1043 3216.056,-810.2936 3227.9392,-800.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"3230.4875,-802.8639 3235.947,-793.784 3226.0168,-797.4775 3230.4875,-802.8639\" stroke=\"#000000\"/>\n</g>\n<!-- 140252874312728 -->\n<g class=\"node\" id=\"node18\">\n<title>140252874312728</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 504,-710.5 504,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-683.8\">global_average_pooling1d_5: GlobalAveragePooling1D</text>\n<polyline fill=\"none\" points=\"344,-664.5 344,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"344,-687.5 402,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"402,-664.5 402,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"402,-687.5 504,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252874209656&#45;&gt;140252874312728 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140252874209656-&gt;140252874312728</title>\n<path d=\"M614.8317,-747.4901C548.4565,-736.5157 468.9664,-723.3729 401.3293,-712.1899\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"401.8761,-708.7329 391.4391,-710.5547 400.7342,-715.6391 401.8761,-708.7329\" stroke=\"#000000\"/>\n</g>\n<!-- 140252874035328 -->\n<g class=\"node\" id=\"node19\">\n<title>140252874035328</title>\n<polygon fill=\"none\" points=\"522,-664.5 522,-710.5 986,-710.5 986,-664.5 522,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-683.8\">global_max_pooling1d_5: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"826,-664.5 826,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"826,-687.5 884,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"884,-664.5 884,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"884,-687.5 986,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252874209656&#45;&gt;140252874035328 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140252874209656-&gt;140252874035328</title>\n<path d=\"M754,-747.3799C754,-739.1745 754,-729.7679 754,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"757.5001,-720.784 754,-710.784 750.5001,-720.784 757.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873362624 -->\n<g class=\"node\" id=\"node20\">\n<title>140252873362624</title>\n<polygon fill=\"none\" points=\"1004,-664.5 1004,-710.5 1508,-710.5 1508,-664.5 1004,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1176\" y=\"-683.8\">global_average_pooling1d_6: GlobalAveragePooling1D</text>\n<polyline fill=\"none\" points=\"1348,-664.5 1348,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1377\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"1348,-687.5 1406,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1377\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"1406,-664.5 1406,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1457\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"1406,-687.5 1508,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1457\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252873759488&#45;&gt;140252873362624 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140252873759488-&gt;140252873362624</title>\n<path d=\"M1557.396,-747.4901C1502.8246,-736.6282 1437.581,-723.642 1381.7745,-712.5343\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1382.3197,-709.0742 1371.8289,-710.5547 1380.9532,-715.9395 1382.3197,-709.0742\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873065864 -->\n<g class=\"node\" id=\"node21\">\n<title>140252873065864</title>\n<polygon fill=\"none\" points=\"1526,-664.5 1526,-710.5 1990,-710.5 1990,-664.5 1526,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1678\" y=\"-683.8\">global_max_pooling1d_6: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"1830,-664.5 1830,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1859\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"1830,-687.5 1888,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1859\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"1888,-664.5 1888,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1939\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"1888,-687.5 1990,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1939\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252873759488&#45;&gt;140252873065864 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140252873759488-&gt;140252873065864</title>\n<path d=\"M1696.6772,-747.3799C1705.9937,-738.2827 1716.8223,-727.7088 1726.7646,-718.0005\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1729.4454,-720.2746 1734.1549,-710.784 1724.5549,-715.2663 1729.4454,-720.2746\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872996792 -->\n<g class=\"node\" id=\"node22\">\n<title>140252872996792</title>\n<polygon fill=\"none\" points=\"2008,-664.5 2008,-710.5 2512,-710.5 2512,-664.5 2008,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2180\" y=\"-683.8\">global_average_pooling1d_7: GlobalAveragePooling1D</text>\n<polyline fill=\"none\" points=\"2352,-664.5 2352,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2381\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"2352,-687.5 2410,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2381\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"2410,-664.5 2410,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2461\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"2410,-687.5 2512,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2461\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252872917400&#45;&gt;140252872996792 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140252872917400-&gt;140252872996792</title>\n<path d=\"M2459.4851,-747.4901C2424.3381,-736.9205 2382.5025,-724.3395 2346.2422,-713.4352\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2347.248,-710.0829 2336.6637,-710.5547 2345.2321,-716.7863 2347.248,-710.0829\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872718656 -->\n<g class=\"node\" id=\"node23\">\n<title>140252872718656</title>\n<polygon fill=\"none\" points=\"2530,-664.5 2530,-710.5 2994,-710.5 2994,-664.5 2530,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2682\" y=\"-683.8\">global_max_pooling1d_7: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"2834,-664.5 2834,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2863\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"2834,-687.5 2892,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2863\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"2892,-664.5 2892,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2943\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"2892,-687.5 2994,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2943\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252872917400&#45;&gt;140252872718656 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140252872917400-&gt;140252872718656</title>\n<path d=\"M2598.6535,-747.4901C2626.821,-737.1454 2660.2347,-724.874 2689.4801,-714.1334\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2691.0443,-717.2876 2699.2246,-710.5547 2688.631,-710.7167 2691.0443,-717.2876\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872027384 -->\n<g class=\"node\" id=\"node24\">\n<title>140252872027384</title>\n<polygon fill=\"none\" points=\"3012,-664.5 3012,-710.5 3516,-710.5 3516,-664.5 3012,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3184\" y=\"-683.8\">global_average_pooling1d_8: GlobalAveragePooling1D</text>\n<polyline fill=\"none\" points=\"3356,-664.5 3356,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3385\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"3356,-687.5 3414,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3385\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"3414,-664.5 3414,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3465\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"3414,-687.5 3516,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3465\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252872427000&#45;&gt;140252872027384 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140252872427000-&gt;140252872027384</title>\n<path d=\"M3264,-747.3799C3264,-739.1745 3264,-729.7679 3264,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"3267.5001,-720.784 3264,-710.784 3260.5001,-720.784 3267.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872257888 -->\n<g class=\"node\" id=\"node25\">\n<title>140252872257888</title>\n<polygon fill=\"none\" points=\"3534,-664.5 3534,-710.5 3998,-710.5 3998,-664.5 3534,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3686\" y=\"-683.8\">global_max_pooling1d_8: GlobalMaxPooling1D</text>\n<polyline fill=\"none\" points=\"3838,-664.5 3838,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3867\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"3838,-687.5 3896,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3867\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"3896,-664.5 3896,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3947\" y=\"-695.3\">(None, 50, 32)</text>\n<polyline fill=\"none\" points=\"3896,-687.5 3998,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"3947\" y=\"-672.3\">(None, 32)</text>\n</g>\n<!-- 140252872427000&#45;&gt;140252872257888 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140252872427000-&gt;140252872257888</title>\n<path d=\"M3403.1683,-747.4901C3469.5435,-736.5157 3549.0336,-723.3729 3616.6707,-712.1899\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"3617.2658,-715.6391 3626.5609,-710.5547 3616.1239,-708.7329 3617.2658,-715.6391\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872260352 -->\n<g class=\"node\" id=\"node26\">\n<title>140252872260352</title>\n<polygon fill=\"none\" points=\"1601.5,-581.5 1601.5,-627.5 2416.5,-627.5 2416.5,-581.5 1601.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1689\" y=\"-600.8\">concatenate_2: Concatenate</text>\n<polyline fill=\"none\" points=\"1776.5,-581.5 1776.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1805.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"1776.5,-604.5 1834.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1805.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"1834.5,-581.5 1834.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2125.5\" y=\"-612.3\">[(None, 32), (None, 32), (None, 32), (None, 32), (None, 32), (None, 32), (None, 32), (None, 32)]</text>\n<polyline fill=\"none\" points=\"1834.5,-604.5 2416.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2125.5\" y=\"-589.3\">(None, 256)</text>\n</g>\n<!-- 140252874312728&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140252874312728-&gt;140252872260352</title>\n<path d=\"M504.0945,-664.5901C507.0795,-664.3883 510.049,-664.1914 513,-664 876.7058,-640.4083 1290.8022,-624.8098 1590.9716,-615.526\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1591.2679,-619.0187 1601.1553,-615.2121 1591.0522,-612.022 1591.2679,-619.0187\" stroke=\"#000000\"/>\n</g>\n<!-- 140252874035328&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge26\">\n<title>140252874035328-&gt;140252872260352</title>\n<path d=\"M986.1427,-664.7018C989.1127,-664.4631 992.0662,-664.229 995,-664 1190.8309,-648.7124 1408.217,-635.4638 1591.3256,-625.3741\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1591.6046,-628.8641 1601.3974,-624.8204 1591.2203,-621.8747 1591.6046,-628.8641\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873362624&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge27\">\n<title>140252873362624-&gt;140252872260352</title>\n<path d=\"M1464.7525,-664.4901C1565.9507,-653.3354 1687.473,-639.9406 1789.9912,-628.6404\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1790.6116,-632.0933 1800.168,-627.5187 1789.8447,-625.1355 1790.6116,-632.0933\" stroke=\"#000000\"/>\n</g>\n<!-- 140252873065864&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge28\">\n<title>140252873065864-&gt;140252872260352</title>\n<path d=\"M1827.5842,-664.4901C1859.2756,-654.0105 1896.9466,-641.5535 1929.7265,-630.7139\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1930.885,-634.0173 1939.2805,-627.5547 1928.6872,-627.3713 1930.885,-634.0173\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872996792&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge29\">\n<title>140252872996792-&gt;140252872260352</title>\n<path d=\"M2190.4158,-664.4901C2158.7244,-654.0105 2121.0534,-641.5535 2088.2735,-630.7139\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2089.3128,-627.3713 2078.7195,-627.5547 2087.115,-634.0173 2089.3128,-627.3713\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872718656&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge30\">\n<title>140252872718656-&gt;140252872260352</title>\n<path d=\"M2553.2475,-664.4901C2452.0493,-653.3354 2330.527,-639.9406 2228.0088,-628.6404\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2228.1553,-625.1355 2217.832,-627.5187 2227.3884,-632.0933 2228.1553,-625.1355\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872027384&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge31\">\n<title>140252872027384-&gt;140252872260352</title>\n<path d=\"M3011.8996,-664.6744C3008.9164,-664.4459 3005.949,-664.221 3003,-664 2813.9231,-649.8321 2604.4106,-636.8829 2426.6772,-626.7086\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2426.8146,-623.2109 2416.6312,-626.1346 2426.4152,-630.1995 2426.8146,-623.2109\" stroke=\"#000000\"/>\n</g>\n<!-- 140252872257888&#45;&gt;140252872260352 -->\n<g class=\"edge\" id=\"edge32\">\n<title>140252872257888-&gt;140252872260352</title>\n<path d=\"M3533.8632,-664.621C3530.8914,-664.4078 3527.9359,-664.2006 3525,-664 3154.2504,-638.6698 2731.7023,-623.1876 2427.0557,-614.392\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2426.8175,-610.8838 2416.721,-614.0949 2426.6163,-617.8809 2426.8175,-610.8838\" stroke=\"#000000\"/>\n</g>\n<!-- 140252871885096 -->\n<g class=\"node\" id=\"node27\">\n<title>140252871885096</title>\n<polygon fill=\"none\" points=\"1801,-498.5 1801,-544.5 2217,-544.5 2217,-498.5 1801,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1936.5\" y=\"-517.8\">batch_normalization_3: BatchNormalization</text>\n<polyline fill=\"none\" points=\"2072,-498.5 2072,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2101\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"2072,-521.5 2130,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2101\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"2130,-498.5 2130,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2173.5\" y=\"-529.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"2130,-521.5 2217,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2173.5\" y=\"-506.3\">(None, 256)</text>\n</g>\n<!-- 140252872260352&#45;&gt;140252871885096 -->\n<g class=\"edge\" id=\"edge33\">\n<title>140252872260352-&gt;140252871885096</title>\n<path d=\"M2009,-581.3799C2009,-573.1745 2009,-563.7679 2009,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-554.784 2009,-544.784 2005.5001,-554.784 2012.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252871974360 -->\n<g class=\"node\" id=\"node28\">\n<title>140252871974360</title>\n<polygon fill=\"none\" points=\"1883,-415.5 1883,-461.5 2135,-461.5 2135,-415.5 1883,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1936.5\" y=\"-434.8\">dense_4: Dense</text>\n<polyline fill=\"none\" points=\"1990,-415.5 1990,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2019\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"1990,-438.5 2048,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2019\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"2048,-415.5 2048,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-446.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"2048,-438.5 2135,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-423.3\">(None, 64)</text>\n</g>\n<!-- 140252871885096&#45;&gt;140252871974360 -->\n<g class=\"edge\" id=\"edge34\">\n<title>140252871885096-&gt;140252871974360</title>\n<path d=\"M2009,-498.3799C2009,-490.1745 2009,-480.7679 2009,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-471.784 2009,-461.784 2005.5001,-471.784 2012.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252871887504 -->\n<g class=\"node\" id=\"node29\">\n<title>140252871887504</title>\n<polygon fill=\"none\" points=\"1873,-332.5 1873,-378.5 2145,-378.5 2145,-332.5 1873,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1940\" y=\"-351.8\">dropout_3: Dropout</text>\n<polyline fill=\"none\" points=\"2007,-332.5 2007,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2036\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"2007,-355.5 2065,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2036\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"2065,-332.5 2065,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2105\" y=\"-363.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"2065,-355.5 2145,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2105\" y=\"-340.3\">(None, 64)</text>\n</g>\n<!-- 140252871974360&#45;&gt;140252871887504 -->\n<g class=\"edge\" id=\"edge35\">\n<title>140252871974360-&gt;140252871887504</title>\n<path d=\"M2009,-415.3799C2009,-407.1745 2009,-397.7679 2009,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-388.784 2009,-378.784 2005.5001,-388.784 2012.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252871587880 -->\n<g class=\"node\" id=\"node30\">\n<title>140252871587880</title>\n<polygon fill=\"none\" points=\"1804.5,-249.5 1804.5,-295.5 2213.5,-295.5 2213.5,-249.5 1804.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1940\" y=\"-268.8\">batch_normalization_4: BatchNormalization</text>\n<polyline fill=\"none\" points=\"2075.5,-249.5 2075.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2104.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"2075.5,-272.5 2133.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2104.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"2133.5,-249.5 2133.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2173.5\" y=\"-280.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"2133.5,-272.5 2213.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2173.5\" y=\"-257.3\">(None, 64)</text>\n</g>\n<!-- 140252871887504&#45;&gt;140252871587880 -->\n<g class=\"edge\" id=\"edge36\">\n<title>140252871887504-&gt;140252871587880</title>\n<path d=\"M2009,-332.3799C2009,-324.1745 2009,-314.7679 2009,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-305.784 2009,-295.784 2005.5001,-305.784 2012.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252870904408 -->\n<g class=\"node\" id=\"node31\">\n<title>140252870904408</title>\n<polygon fill=\"none\" points=\"1886.5,-166.5 1886.5,-212.5 2131.5,-212.5 2131.5,-166.5 1886.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1940\" y=\"-185.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"1993.5,-166.5 1993.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2022.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"1993.5,-189.5 2051.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2022.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"2051.5,-166.5 2051.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-197.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"2051.5,-189.5 2131.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-174.3\">(None, 32)</text>\n</g>\n<!-- 140252871587880&#45;&gt;140252870904408 -->\n<g class=\"edge\" id=\"edge37\">\n<title>140252871587880-&gt;140252870904408</title>\n<path d=\"M2009,-249.3799C2009,-241.1745 2009,-231.7679 2009,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-222.784 2009,-212.784 2005.5001,-222.784 2012.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252870753864 -->\n<g class=\"node\" id=\"node32\">\n<title>140252870753864</title>\n<polygon fill=\"none\" points=\"1873,-83.5 1873,-129.5 2145,-129.5 2145,-83.5 1873,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1940\" y=\"-102.8\">dropout_4: Dropout</text>\n<polyline fill=\"none\" points=\"2007,-83.5 2007,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2036\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"2007,-106.5 2065,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2036\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"2065,-83.5 2065,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2105\" y=\"-114.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"2065,-106.5 2145,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2105\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140252870904408&#45;&gt;140252870753864 -->\n<g class=\"edge\" id=\"edge38\">\n<title>140252870904408-&gt;140252870753864</title>\n<path d=\"M2009,-166.3799C2009,-158.1745 2009,-148.7679 2009,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-139.784 2009,-129.784 2005.5001,-139.784 2012.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140252870690296 -->\n<g class=\"node\" id=\"node33\">\n<title>140252870690296</title>\n<polygon fill=\"none\" points=\"1886.5,-.5 1886.5,-46.5 2131.5,-46.5 2131.5,-.5 1886.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1940\" y=\"-19.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"1993.5,-.5 1993.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2022.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"1993.5,-23.5 2051.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2022.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"2051.5,-.5 2051.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"2051.5,-23.5 2131.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2091.5\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 140252870753864&#45;&gt;140252870690296 -->\n<g class=\"edge\" id=\"edge39\">\n<title>140252870753864-&gt;140252870690296</title>\n<path d=\"M2009,-83.3799C2009,-75.1745 2009,-65.7679 2009,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"2012.5001,-56.784 2009,-46.784 2005.5001,-56.784 2012.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "bHYz1kXFLhIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "6725ec18-4bb2-4a1d-9c86-2608b0d88d78"
      },
      "cell_type": "code",
      "source": [
        "test_preds = np.zeros((test.shape[0], 5))\n",
        "file_path = \"/content/drive/My Drive/DeepLearning/best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 2)\n",
        "\n",
        "print(\"Building the model...\")\n",
        "model2 = build_model2(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)\n",
        "\n",
        "for i in range(NUM_FOLDS):\n",
        "    print(\"FOLD\", i+1)    \n",
        "    print(\"Splitting the data into train and validation...\")\n",
        "    train_seq, val_seq = X_train[train[\"fold_id\"] != i], X_train[train[\"fold_id\"] == i]\n",
        "    y_train = ohe.transform(train[train[\"fold_id\"] != i][\"Sentiment\"].values.reshape(-1, 1))\n",
        "    y_val = ohe.transform(train[train[\"fold_id\"] == i][\"Sentiment\"].values.reshape(-1, 1))        \n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model2.fit(train_seq, y_train, validation_data = (val_seq, y_val), batch_size = 128, epochs = 15, verbose = 1, callbacks = [early_stop]) \n",
        "    model2.save_weights(file_path)  \n",
        "    test_preds += model2.predict([X_test], batch_size=1024, verbose=1)    \n",
        "    print()\n",
        "    \n",
        "print(\"Save model after cross-validation...\")\n",
        "model2.save_weights(file_path)   \n",
        "test_preds /= NUM_FOLDS\n",
        "\n",
        "\n",
        "print(\"Make the submission ready...\")\n",
        "sub = pd.read_csv('/content/drive/My Drive/DeepLearning/sampleSubmission.csv', sep=\",\")\n",
        "\n",
        "pred = model2.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "sub['Sentiment'] = predictions\n",
        "sub.to_csv(\"/content/drive/My Drive/DeepLearning/blend.csv\", index=False)\n",
        "\n",
        "predictions = np.round(np.argmax(test_preds, axis=1)).astype(int)\n",
        "sub['Sentiment'] = predictions\n",
        "sub.to_csv(\"/content/drive/My Drive/DeepLearning/avg_blend.csv\", index=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building the model...\n",
            "FOLD 1\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125230 samples, validate on 30830 samples\n",
            "Epoch 1/15\n",
            "125230/125230 [==============================] - 88s 703us/step - loss: 0.3736 - acc: 0.8326 - val_loss: 0.3258 - val_acc: 0.8490\n",
            "Epoch 2/15\n",
            "125230/125230 [==============================] - 79s 633us/step - loss: 0.3305 - acc: 0.8505 - val_loss: 0.3067 - val_acc: 0.8609\n",
            "Epoch 3/15\n",
            "125230/125230 [==============================] - 79s 634us/step - loss: 0.3202 - acc: 0.8535 - val_loss: 0.3108 - val_acc: 0.8611\n",
            "Epoch 4/15\n",
            "125230/125230 [==============================] - 80s 635us/step - loss: 0.3128 - acc: 0.8570 - val_loss: 0.3009 - val_acc: 0.8625\n",
            "Epoch 5/15\n",
            "125230/125230 [==============================] - 79s 633us/step - loss: 0.3062 - acc: 0.8598 - val_loss: 0.3019 - val_acc: 0.8654\n",
            "Epoch 6/15\n",
            "125230/125230 [==============================] - 79s 632us/step - loss: 0.3013 - acc: 0.8615 - val_loss: 0.2953 - val_acc: 0.8645\n",
            "Epoch 7/15\n",
            "125230/125230 [==============================] - 79s 633us/step - loss: 0.2969 - acc: 0.8637 - val_loss: 0.2943 - val_acc: 0.8666\n",
            "Epoch 8/15\n",
            "125230/125230 [==============================] - 80s 636us/step - loss: 0.2930 - acc: 0.8659 - val_loss: 0.3009 - val_acc: 0.8623\n",
            "Epoch 9/15\n",
            "125230/125230 [==============================] - 80s 636us/step - loss: 0.2900 - acc: 0.8671 - val_loss: 0.2898 - val_acc: 0.8688\n",
            "Epoch 10/15\n",
            "125230/125230 [==============================] - 79s 631us/step - loss: 0.2858 - acc: 0.8692 - val_loss: 0.2994 - val_acc: 0.8645\n",
            "Epoch 11/15\n",
            "125230/125230 [==============================] - 79s 633us/step - loss: 0.2842 - acc: 0.8693 - val_loss: 0.2909 - val_acc: 0.8699\n",
            "66292/66292 [==============================] - 8s 117us/step\n",
            "\n",
            "FOLD 2\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124608 samples, validate on 31452 samples\n",
            "Epoch 1/15\n",
            "124608/124608 [==============================] - 81s 647us/step - loss: 0.2863 - acc: 0.8692 - val_loss: 0.2571 - val_acc: 0.8850\n",
            "Epoch 2/15\n",
            "124608/124608 [==============================] - 79s 634us/step - loss: 0.2841 - acc: 0.8703 - val_loss: 0.2593 - val_acc: 0.8839\n",
            "Epoch 3/15\n",
            "124608/124608 [==============================] - 79s 635us/step - loss: 0.2813 - acc: 0.8720 - val_loss: 0.2650 - val_acc: 0.8812\n",
            "66292/66292 [==============================] - 5s 79us/step\n",
            "\n",
            "FOLD 3\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125022 samples, validate on 31038 samples\n",
            "Epoch 1/15\n",
            "125022/125022 [==============================] - 81s 645us/step - loss: 0.2827 - acc: 0.8706 - val_loss: 0.2517 - val_acc: 0.8869\n",
            "Epoch 2/15\n",
            "125022/125022 [==============================] - 79s 635us/step - loss: 0.2795 - acc: 0.8726 - val_loss: 0.2508 - val_acc: 0.8862\n",
            "Epoch 3/15\n",
            "125022/125022 [==============================] - 79s 634us/step - loss: 0.2772 - acc: 0.8740 - val_loss: 0.2506 - val_acc: 0.8871\n",
            "Epoch 4/15\n",
            "125022/125022 [==============================] - 79s 635us/step - loss: 0.2762 - acc: 0.8746 - val_loss: 0.2506 - val_acc: 0.8860\n",
            "Epoch 5/15\n",
            "125022/125022 [==============================] - 79s 634us/step - loss: 0.2743 - acc: 0.8762 - val_loss: 0.2509 - val_acc: 0.8865\n",
            "66292/66292 [==============================] - 5s 79us/step\n",
            "\n",
            "FOLD 4\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124609 samples, validate on 31451 samples\n",
            "Epoch 1/15\n",
            "124609/124609 [==============================] - 80s 641us/step - loss: 0.2747 - acc: 0.8753 - val_loss: 0.2438 - val_acc: 0.8920\n",
            "Epoch 2/15\n",
            "124609/124609 [==============================] - 79s 632us/step - loss: 0.2727 - acc: 0.8758 - val_loss: 0.2444 - val_acc: 0.8907\n",
            "Epoch 3/15\n",
            "124609/124609 [==============================] - 79s 636us/step - loss: 0.2714 - acc: 0.8769 - val_loss: 0.2487 - val_acc: 0.8891\n",
            "66292/66292 [==============================] - 5s 79us/step\n",
            "\n",
            "FOLD 5\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124771 samples, validate on 31289 samples\n",
            "Epoch 1/15\n",
            "124771/124771 [==============================] - 80s 638us/step - loss: 0.2721 - acc: 0.8771 - val_loss: 0.2358 - val_acc: 0.8941\n",
            "Epoch 2/15\n",
            "124771/124771 [==============================] - 79s 637us/step - loss: 0.2694 - acc: 0.8787 - val_loss: 0.2402 - val_acc: 0.8928\n",
            "Epoch 3/15\n",
            "124771/124771 [==============================] - 79s 633us/step - loss: 0.2683 - acc: 0.8790 - val_loss: 0.2407 - val_acc: 0.8916\n",
            "66292/66292 [==============================] - 5s 79us/step\n",
            "\n",
            "Save model after cross-validation...\n",
            "Make the submission ready...\n",
            "66292/66292 [==============================] - 5s 79us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w_Qgo7qZjPbh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model3 \n",
        "LSTM + DCNN\n",
        "loss: 0.7205 - acc: 0.6998 - val_loss: 0.6625 - val_acc: 0.7189"
      ]
    },
    {
      "metadata": {
        "id": "Xby86sUKw4yg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model3(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
        "    input_words = Input((max_len, ))\n",
        "    x_words = Embedding(19479, embed_size,weights=[embedding_matrix],trainable=False)(input_words)\n",
        "    x_words = SpatialDropout1D(0.3)(x_words)\n",
        "    x_words = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x_words)\n",
        "    x_words = Dropout(0.2)(x_words)\n",
        "    x_words = Conv1D(256, 3, strides = 1,  padding='causal', activation='relu', )(x_words)\n",
        "    x_words = Conv1D(128, 3, strides = 1,  padding='causal', activation='relu', )(x_words)\n",
        "    x_words = Conv1D(64, 3, strides = 1,   padding='causal', activation='relu', )(x_words)\n",
        "    x_words = GlobalMaxPool1D()(x_words)\n",
        "    x_words = Dropout(0.2)(x_words)\n",
        "\n",
        "    x = Dense(50, activation=\"relu\")(x_words)\n",
        "    x = Dropout(0.2)(x)\n",
        "    predictions = Dense(5, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=[input_words], outputs=predictions)\n",
        "    model.compile(optimizer='nadam' ,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DW0yUd03xrP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "f1b28bde-3ed9-487a-d66e-d07388221d44"
      },
      "cell_type": "code",
      "source": [
        "model3 = build_model3(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)\n",
        "\n",
        "history = model.fit([X_train_words], X_train_target_binary, epochs=nb_epoch, verbose=1, batch_size = 1024, callbacks=[early_stop], validation_split = 0.2, shuffle=True)\n",
        "history = model3.fit(train_seq, y_train, validation_data = (val_seq, y_val), batch_size = 128, epochs = 15, verbose = 1, callbacks = [early_stop]) \n",
        "train_loss = np.mean(history.history['loss'])\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "print('Train loss: %f' % (train_loss*100))\n",
        "print('Validation loss: %f' % (val_loss*100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2c6f06688bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_target_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#history = model.fit(X_train_words, X_train_target_binary, epochs=10, verbose=1, batch_size = 512,  validation_split = 0.1, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nZB9ZOYE47gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1275
        },
        "outputId": "5120f18e-5dfc-4465-8007-06d6b18089e5"
      },
      "cell_type": "code",
      "source": [
        "test_preds = np.zeros((test.shape[0], 5))\n",
        "file_path = \"/content/drive/My Drive/DeepLearning/best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = True, mode = \"min\")\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode=\"min\", patience = 3, verbose=1)\n",
        "\n",
        "print(\"Building the model...\")\n",
        "model3 = build_model3(lr = 1e-3, lr_d = 0, units = 64, spatial_dr = 0.5, kernel_size1=3, kernel_size2=3, dense_units=64, dr=0.3, conv_size=32)\n",
        "\n",
        "for i in range(NUM_FOLDS):\n",
        "    print(\"FOLD\", i+1)    \n",
        "    print(\"Splitting the data into train and validation...\")\n",
        "    train_seq, val_seq = X_train[train[\"fold_id\"] != i], X_train[train[\"fold_id\"] == i]\n",
        "    y_train = ohe.transform(train[train[\"fold_id\"] != i][\"Sentiment\"].values.reshape(-1, 1))\n",
        "    y_val = ohe.transform(train[train[\"fold_id\"] == i][\"Sentiment\"].values.reshape(-1, 1))        \n",
        "    \n",
        "    print(\"Training the model...\")\n",
        "    model3.fit(train_seq, y_train, validation_data = (val_seq, y_val), batch_size = 128, epochs = 15, verbose = 1, callbacks = [early_stop]) \n",
        "    model3.save_weights(file_path)  \n",
        "    test_preds += model3.predict([X_test], batch_size=1024, verbose=1)    \n",
        "    print()\n",
        "    \n",
        "print(\"Save model after cross-validation...\")\n",
        "model3.save_weights(file_path)   \n",
        "test_preds /= NUM_FOLDS\n",
        "\n",
        "\n",
        "print(\"Make the submission ready...\")\n",
        "sub = pd.read_csv('/content/drive/My Drive/DeepLearning/sampleSubmission.csv', sep=\",\")\n",
        "\n",
        "pred = model3.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
        "sub['Sentiment'] = predictions\n",
        "sub.to_csv(\"/content/drive/My Drive/DeepLearning/blend.csv\", index=False)\n",
        "\n",
        "predictions = np.round(np.argmax(test_preds, axis=1)).astype(int)\n",
        "sub['Sentiment'] = predictions\n",
        "sub.to_csv(\"/content/drive/My Drive/DeepLearning/avg_blend.csv\", index=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building the model...\n",
            "FOLD 1\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125230 samples, validate on 30830 samples\n",
            "Epoch 1/15\n",
            "125230/125230 [==============================] - 46s 366us/step - loss: 0.9709 - acc: 0.5990 - val_loss: 0.8935 - val_acc: 0.6251\n",
            "Epoch 2/15\n",
            "125230/125230 [==============================] - 40s 322us/step - loss: 0.8800 - acc: 0.6357 - val_loss: 0.8489 - val_acc: 0.6488\n",
            "Epoch 3/15\n",
            "125230/125230 [==============================] - 40s 321us/step - loss: 0.8414 - acc: 0.6511 - val_loss: 0.8371 - val_acc: 0.6549\n",
            "Epoch 4/15\n",
            "125230/125230 [==============================] - 40s 321us/step - loss: 0.8159 - acc: 0.6616 - val_loss: 0.8279 - val_acc: 0.6561\n",
            "Epoch 5/15\n",
            "125230/125230 [==============================] - 40s 321us/step - loss: 0.7955 - acc: 0.6676 - val_loss: 0.8275 - val_acc: 0.6587\n",
            "Epoch 6/15\n",
            "125230/125230 [==============================] - 40s 322us/step - loss: 0.7816 - acc: 0.6741 - val_loss: 0.8235 - val_acc: 0.6600\n",
            "Epoch 7/15\n",
            "125230/125230 [==============================] - 40s 323us/step - loss: 0.7671 - acc: 0.6804 - val_loss: 0.8327 - val_acc: 0.6608\n",
            "Epoch 8/15\n",
            "125230/125230 [==============================] - 40s 322us/step - loss: 0.7576 - acc: 0.6847 - val_loss: 0.8334 - val_acc: 0.6623\n",
            "66292/66292 [==============================] - 4s 54us/step\n",
            "\n",
            "FOLD 2\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124608 samples, validate on 31452 samples\n",
            "Epoch 1/15\n",
            "124608/124608 [==============================] - 41s 326us/step - loss: 0.7761 - acc: 0.6783 - val_loss: 0.7067 - val_acc: 0.7130\n",
            "Epoch 2/15\n",
            "124608/124608 [==============================] - 40s 322us/step - loss: 0.7584 - acc: 0.6843 - val_loss: 0.7185 - val_acc: 0.7009\n",
            "Epoch 3/15\n",
            "124608/124608 [==============================] - 40s 322us/step - loss: 0.7486 - acc: 0.6889 - val_loss: 0.7210 - val_acc: 0.7015\n",
            "66292/66292 [==============================] - 3s 47us/step\n",
            "\n",
            "FOLD 3\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 125022 samples, validate on 31038 samples\n",
            "Epoch 1/15\n",
            "125022/125022 [==============================] - 41s 325us/step - loss: 0.7590 - acc: 0.6859 - val_loss: 0.6695 - val_acc: 0.7249\n",
            "Epoch 2/15\n",
            "125022/125022 [==============================] - 40s 321us/step - loss: 0.7492 - acc: 0.6886 - val_loss: 0.6859 - val_acc: 0.7142\n",
            "Epoch 3/15\n",
            "125022/125022 [==============================] - 40s 320us/step - loss: 0.7390 - acc: 0.6918 - val_loss: 0.6826 - val_acc: 0.7144\n",
            "66292/66292 [==============================] - 3s 48us/step\n",
            "\n",
            "FOLD 4\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124609 samples, validate on 31451 samples\n",
            "Epoch 1/15\n",
            "124609/124609 [==============================] - 41s 327us/step - loss: 0.7406 - acc: 0.6922 - val_loss: 0.6621 - val_acc: 0.7266\n",
            "Epoch 2/15\n",
            "124609/124609 [==============================] - 40s 322us/step - loss: 0.7346 - acc: 0.6959 - val_loss: 0.6731 - val_acc: 0.7186\n",
            "Epoch 3/15\n",
            "124609/124609 [==============================] - 40s 321us/step - loss: 0.7292 - acc: 0.6982 - val_loss: 0.6777 - val_acc: 0.7146\n",
            "66292/66292 [==============================] - 3s 47us/step\n",
            "\n",
            "FOLD 5\n",
            "Splitting the data into train and validation...\n",
            "Training the model...\n",
            "Train on 124771 samples, validate on 31289 samples\n",
            "Epoch 1/15\n",
            "124771/124771 [==============================] - 41s 326us/step - loss: 0.7309 - acc: 0.6980 - val_loss: 0.6523 - val_acc: 0.7281\n",
            "Epoch 2/15\n",
            "124771/124771 [==============================] - 40s 321us/step - loss: 0.7263 - acc: 0.6981 - val_loss: 0.6621 - val_acc: 0.7269\n",
            "Epoch 3/15\n",
            "124771/124771 [==============================] - 40s 321us/step - loss: 0.7205 - acc: 0.6998 - val_loss: 0.6625 - val_acc: 0.7189\n",
            "66292/66292 [==============================] - 3s 48us/step\n",
            "\n",
            "Save model after cross-validation...\n",
            "Make the submission ready...\n",
            "66292/66292 [==============================] - 3s 47us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}